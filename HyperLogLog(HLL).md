# ⭐ HyperLogLog（HLL）——从头开始的完整讲解

我们要解决的问题是：

> **如何在极小内存下，快速估算“去重后有多少个不同元素”？**
>  （例如统计网站 UV）

普通做法要存所有 ID → 很耗内存。
 HLL 的做法 → **16 KB 就能估算数千万、上亿的去重数量**。

靠什么做到的？
 靠下面几个核心点：

------

# 1️⃣ **哈希成随机二进制串：把每个元素变成“随机硬币序列”**

假设用户 ID = 123
 做哈希 → 得到 64-bit 随机二进制：

```
010101110101011001001000001000101000100...
```

因为哈希均匀，所以这串二进制就像：

> **抛硬币得到的随机序列**

------

# 2️⃣ **用“尾部连续 0 的个数”估算元素数量**

例子：

- `...100` → 2 个连续 0
- `...10000` → 4 个连续 0
- `...10000000` → 7 个连续 0

为什么可以这样估算？

因为：

> 随机二进制串尾部出现 n 个连续 0 的概率 = **1 / 2ⁿ**

例如：

- 末尾是 `0`（1 个零）：概率 1/2
- 末尾是 `00`（2 个零）：概率 1/4
- 末尾是 `000000`（6 个零）：概率 1/64
- 末尾是 `0000000000`（10 个零）：概率 1/1024

所以如果你看到过**一个串尾部有 n 个零**，说明：

> 很可能你已经看过了大约 **2ⁿ** 个不同元素。

⚠ 但这个估计很不稳定！

------

# 3️⃣ **为了降低误差 → 分成 16384 个桶（registers）**

我们不能只用一个“最大零”估计，因为运气影响太大。

解决方法：

> 把所有数据随机分到很多桶中，让每个桶独立估计。
>  最后把所有桶的估计合并 → 误差大幅减少。

怎么分桶？

在哈希串中：

```
[ 前14位 ] [ 后面所有位 ]
   |           |
  桶ID      用来统计零数量
```

- 前 14 bit = 2¹⁴ = **16384 个桶**
- 后面 50 bit → 用于计算连续零

为什么用前14位不影响后面统计？
 👉 因为哈希的每一位都是独立随机的。
 前 14 位随机分桶，后 50 位用于统计零 → **互不干扰**。

------

# 4️⃣ **每个桶记录“自己看到的最长连续零数”**

示例：

桶 0 → 看过的最大尾零 = 4
 桶 1 → 看过的最大尾零 = 7
 桶 2 → 看过的最大尾零 = 6
 …
 桶 8000 → 看过的最大尾零 = 3
 ...

每个桶其实都在做一场独立实验：

> “我这里的随机数里，最长尾零有几位？”

因为桶多，这些独立实验的结果汇总后更稳健。

------

# 5️⃣ **数学上：桶越多，误差越低**

HyperLogLog 的误差公式：

误差≈1.04m\text{误差} \approx \frac{1.04}{\sqrt{m}}误差≈m1.04

m = 桶数

| m（桶数）               | 误差     |
| ----------------------- | -------- |
| 128                     | 9%       |
| 1024                    | 3%       |
| 4096                    | 1.6%     |
| **16384（Redis 默认）** | **0.8%** |

**桶越多 → √m 越大 → 误差越低**
 很直观。

------

# 6️⃣ **合并桶结果时，用“调和平均”（Harmonic Mean）**

普通平均为什么不行？

因为个别“极端幸运的桶”会看到非常大的尾零：
 例如：

```
桶1 = 4
桶2 = 5
桶3 = 6
桶4 = 12   ← 运气好爆了！
```

如果你做普通平均：

```
(4 + 5 + 6 + 12) / 4 = 6.75
```

被极端值 12 拉高。

调和平均：

H=n∑1/xiH = \frac{n}{\sum 1/x_i}H=∑1/xin

极端大的值对倒数贡献很小，不会把整体拉高。
 所以 HLL 选择调和平均。

------

# 7️⃣ **如果把前 30 位用作桶会怎样？**

前 30 位 → 2³⁰ ≈ 10 亿个桶！！

### ✔ 优点：

误差超低 → 几乎精准到 0.0001%

### ❌ 致命缺点：

每个桶要 1 字节：

> 10 亿个桶 ≈ **1GB 内存**

完全不现实。

现在的 14 位 → 16384 桶 → 16 KB，就很完美。

------

# 8️⃣ **一张图展示完整的 HLL 哈希格式**

```
64-bit hash:
┌──────────────14-bit──────────────┬──────────────────────50-bit───────────────────────┐
│          bucket index            │         used to count trailing zeros               │
└──────────────────────────────────┴─────────────────────────────────────────────────────┘

例如：

hash = 01010111010101 | 00010000000000000000010000000010000
         ↑ 14bit 桶号        ↑ 用来数尾部连续0的段
```

整个流程非常清晰：

1. 先用前 14 位找到桶编号
2. 再用剩余位统计尾零
3. 更新桶的最大尾零
4. 最后用调和平均合并桶
5. 得到最终估计值

------

# 🟢 **最终总结（最精炼版本）**

### ✔ HLL 的本质：

用“尾部连续零”的稀有程度估算数量。

### ✔ 为什么要 16384 个桶：

独立样本越多 → √m 越大 → 误差更低。

### ✔ 为什么前 14 位分桶不影响后面：

哈希每一位都独立随机。

### ✔ 为什么调和平均：

能抑制极端值（幸运桶）。

### ✔ 为什么不是 30 位桶：

内存爆炸（1GB vs 16KB）。

### ✔ 哈希格式图：

前 14 位做桶索引，后 50 位生成估计值。